#+TITLE: Infrastructure as Code
#+AUTHOR: Dévald Tari
#+DATE: <2025-06-06 Fri 13:00-15:00>
#+REVEAL_ROOT: https://cdn.jsdelivr.net/npm/reveal.js@5.2.1
#+REVEAL_THEME: solarized
#+REVEAL_PLUGINS: (highlight notes)
#+REVEAL_HIGHLIGHT_CSS: https://cdn.jsdelivr.net/npm/highlight.js@11.11.1/styles/base16/solarized-light.min.css
#+OPTIONS: toc:1 num:nil timestamp:nil

* Welcome
Welcome, and thank you for the opportunity to present my Infrastructure as Code demo.

This solution is structured with a client-facing mindset, prioritizing clarity, automation, scalability, and practical consulting value.

#+BEGIN_EXPORT html
<img src="https://avatars.githubusercontent.com/u/13199158"
     alt="Dévald Tari"
     style="display: block; margin-left: auto; margin-right: auto; border-radius: 50%; width: 150px; background-color: #fdf6e3; padding: 6px; box-shadow: 0 0 8px rgba(0,0,0,0.1);" />
#+END_EXPORT

Dévald Tari

#+BEGIN_NOTES
Hello, I’m Dévald Tari. In this short presentation, I’ll walk you through a production-grade Infrastructure-as-Code solution. It reflects my consulting mindset: clarity, scalability, and automation.
#+END_NOTES

* Problem Overview
** Task Goals
The client expects a modular, maintainable, and cloud-native solution to run a one-time web crawler job in AWS.

This solution follows infrastructure-as-code best practices and is presented in the same way I would deliver it to a client.

#+BEGIN_NOTES
Highlight the consulting expectation — this is more than just tech; it's about demonstrating professionalism, modularity, and client-readiness.
#+END_NOTES

** Requirements Recap
- Use =terraform= and optionally =terragrunt=
- Automate provisioning via a CI/CD pipeline
- Store code in Git (mono- or multi-repo)
- Run a simple web crawler
- Output data to an S3 bucket
- Deploy the job to EKS in AWS

#+BEGIN_NOTES
This list should sound familiar to the audience — it sets the expectations and scope clearly before diving into architecture.
#+END_NOTES

* Architecture at a Glance
** High-Level Diagram
#+BEGIN_SRC plantuml :file diagram.svg
@startuml
!theme aws-orange    
actor Dev
Dev -> GitHub: push
GitHub -> AWS: assume OIDC role
GitHub -> Terraform: run plan/apply
Terraform -> EKS: provision cluster + job
EKS -> Job: run crawler
Job -> S3: store results
@enduml
#+END_SRC

#+BEGIN_NOTES
Visual overview to anchor the rest of the presentation.  
CI/CD → EKS → Kubernetes Job → S3  
Includes GitHub, OIDC, Terraform, and cloud services.
#+END_NOTES

** Flow Summary
1. Git push triggers GitHub Actions
2. CI pipeline assumes AWS role using OIDC
3. Terraform (via Terragrunt) provisions infra
4. EKS cluster launches one-shot crawler job
5. Job uploads result to S3

#+BEGIN_NOTES
Walk through these steps from a user/client perspective.  
Reinforce automation, security, and reproducibility.
#+END_NOTES

* Infrastructure Management
** Terragrunt Structure
The codebase is split into a reusable module layer and a =live/= layer using Terragrunt:
- =live/<env>/<region>/<component>=
- Each folder auto-detects its context
- Module sources are versioned and centralized

#+BEGIN_NOTES
Show how this structure helps onboarding and DRY code.  
Explain separation of config and logic.
#+END_NOTES
** Directory layout
#+BEGIN_SRC text
.
├── root.hcl
├── live/
│   └── demo/
│       └── eu-central-1/
│           ├── aws-data/
│           ├── vpc-1/
│           ├── eks-1/
│           ├── crawler-job-1/
│           ├── crawler-s3-1/
│           └── github-oidc/
├── modules/
│   ├── aws-data/
│   ├── crawler-job/
│   └── github-oidc/
#+END_SRC
** Root Logic Sample
The root-level Terragrunt configuration dynamically adjusts behavior based on directory structure and account context — making the setup environment- and region-aware without manual repetition.

#+REVEAL: split

It includes:
- Path introspection to extract environment, region, and component
- Dynamic S3/DynamoDB backend generation (per account)
- AWS provider configuration with consistent tagging

#+BEGIN_NOTES
Explain that this pattern allows any environment (e.g., dev/us-east-1/eks) to self-configure.  
No need to hardcode region/account — it's extracted from path and AWS APIs.  
This makes scaling across accounts and regions much easier in real-world setups.
#+END_NOTES

*** locals
#+BEGIN_SRC hcl
locals {
  path_parts = split("/", path_relative_to_include())

  environment = local.path_parts[1]
  region      = local.path_parts[2]
  component   = local.path_parts[3]
}
#+END_SRC

*** remote state
#+BEGIN_SRC hcl
remote_state {
  backend = "s3"

  generate = {
    path      = "backend.tf"
    if_exists = "overwrite"
  }

  config = {
    encrypt        = true
    region         = local.region
    key            = format("%s/terraform.tfstate", path_relative_to_include())
    bucket         = format("terraform-states-%s", get_aws_account_id())
    dynamodb_table = format("terraform-states-%s", get_aws_account_id())
  }
}
#+END_SRC

*** generate aws provider
#+BEGIN_SRC hcl
generate "provider_aws" {
  path      = "provider_aws.tf"
  if_exists = "overwrite"
  contents  = <<EOF
provider "aws" {
  region  = "${local.region}"

  default_tags {
    tags = {
      Environment = "${local.environment}"
      Region      = "${local.region}"
      Component   = "${local.component}"
      ManagedBy   = "terragrunt/terraform"
    }
  }
}
EOF
}
#+END_SRC

* Continuous Deployment
** GitHub Actions
CI/CD is built with GitHub Actions and OpenID Connect:
- No AWS keys are stored
- Roles are assumed securely at runtime
- Terraform apply runs with permissions scoped per environment

#+BEGIN_NOTES
Mention security and audit compliance.  
Highlight ease of use and GitHub-native flow.
#+END_NOTES

* Infrastructure Modules
** aws-data
The =aws-data= module centralizes the retrieval of region-specific AWS metadata for consistent use across all other infrastructure modules.

#+REVEAL: split

It provides:
- =data.aws_region= → current AWS region name and description
- =data.aws_availability_zones= → list of AZ names and zone IDs

This removes duplication, ensures reliability, and keeps modules clean from boilerplate region logic.

The module is *easily extendable* to include:
- =data.aws_caller_identity= → to expose AWS account ID and user context

#+BEGIN_NOTES
This module embodies the DRY principle — useful in consulting settings to reduce errors and improve reuse across multiple stacks or clients.
Also helps future modules avoid hardcoding or duplicating data lookups.
#+END_NOTES

** github-oidc
The =github-oidc= module provisions an IAM role that allows GitHub Actions to securely authenticate to AWS without long-lived access keys.

#+REVEAL: split

It configures:
- An IAM role with trust policy for GitHub’s OIDC provider
- Conditions based on GitHub repository and branch (audience/subject)
- Minimal required permissions for Terraform plans and deployments

Benefits:
- Eliminates secrets management in CI
- Strong security posture via short-lived tokens
- Fully GitOps-compatible with auditability

#+BEGIN_NOTES
This is critical for secure CI/CD in modern cloud environments.  
GitHub’s native OIDC flow allows your pipeline to assume roles in AWS on-demand — no static credentials needed.  
It’s clean, scalable, and avoids secret sprawl.
#+END_NOTES

** crawler-job
The =crawler-job= module provisions a one-time =Kubernetes Job= on an EKS cluster to run a containerized web crawler.

#+REVEAL: split

It encapsulates:
- A Kubernetes Job spec using a public or custom Docker image
- Environment variable injection and runtime configuration
- Optional TTL and cleanup behavior

Benefits:
- Decouples application logic from infrastructure logic
- Ensures reproducibility and isolation per crawl run
- Fully integrates with Terraform-based provisioning

#+BEGIN_NOTES
This module is tailored for one-off batch tasks in EKS — perfect for ETL, scraping, or similar jobs.  
The advantage is full automation: from cluster provisioning to job execution, all via infrastructure-as-code.  
You can adapt it easily for future use cases, like cron jobs or multi-step workflows.
#+END_NOTES

* Developer Experience
** Nix Environment
Using =nix develop= ensures consistent tools:
- =terraform=, =terragrunt=, =kubectl=, =awscli=
- Works identically in CI and on local machines

#+BEGIN_NOTES
Less friction during onboarding or audits.  
Future team members will appreciate this.
#+END_NOTES
** Local Testing
- The =nix develop= shell offers a reproducible environment for hands-on work
  - From there, you can run arbitrary =terragrunt= commands (e.g. =plan=, =apply=, =destroy=)
- Nix apps like:
  - =nix run .#validate=
  - =nix run .#apply=
    can be run outside the =nix develop= shell as well

#+BEGIN_NOTES
Helps debugging and confidence during delivery.
#+END_NOTES

* Presentation as Code
This presentation was written entirely in =Org Mode= and exported with =ox-reveal= to Reveal.js HTML.

- Edited and versioned in Git
- Live-previewed locally in Emacs
- Structured, reproducible, and hackable
- Reflects the same IaC principles presented here

#+BEGIN_NOTES
A fitting conclusion before Q&A: Not just the infrastructure, but also the delivery itself is code-based.
This shows my consistency in applying IaC values — even to client-facing material.
#+END_NOTES

* Consulting Value
** Business Impact
- Secure, reproducible, modular infrastructure
- Ready to scale to multi-region, multi-account setups
- Aligned with GitOps and compliance needs

** Extendability
- Add Fargate support
- Support multiple job types (e.g. periodic, chained workflows)

#+BEGIN_NOTES
Position the solution as a blueprint for future teams and clients.
#+END_NOTES

* Summary & Q&A
** Recap
- You’ve seen a real-world, production-ready solution
- Security, scalability, and consulting mindset were key

** Questions welcome
#+BEGIN_NOTES
Invite dialogue, welcome technical or strategic questions.
#+END_NOTES
